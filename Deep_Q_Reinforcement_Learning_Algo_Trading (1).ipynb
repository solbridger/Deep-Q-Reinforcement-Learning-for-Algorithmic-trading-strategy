{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Q_Reinforcement_Learning_Algo_Trading.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install alpaca-trade-api\n",
        "!pip install transformers\n",
        "!pip install nltk\n",
        "!pip install ipython ipykernel --upgrade\n",
        "# !pip install pandas-profiling"
      ],
      "metadata": {
        "id": "mG-YX6EtvxXP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b2ddab8-3486-4cba-f60f-19b14cc11628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed huggingface-hub-0.8.1 tokenizers-0.12.1 transformers-4.21.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (7.34.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (5.3.4)\n",
            "Collecting ipykernel\n",
            "  Using cached ipykernel-6.15.1-py3-none-any.whl (132 kB)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython) (5.1.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython) (4.8.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.7/dist-packages (from ipython) (0.1.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython) (4.4.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython) (0.18.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython) (0.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython) (57.4.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython) (2.0.10)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython) (1.15.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from ipykernel) (5.4.8)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (6.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from ipykernel) (21.3)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (23.2.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (6.1.12)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (1.0.0)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (from ipykernel) (1.5.5)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.12->ipykernel) (4.11.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.12->ipykernel) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->ipykernel) (3.0.9)\n",
            "Installing collected packages: ipykernel\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 5.3.4\n",
            "    Uninstalling ipykernel-5.3.4:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import alpaca_trade_api as alp\n",
        "from transformers import pipeline\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import sys, os, glob, random, time, datetime\n",
        "import numpy as np\n",
        "import sklearn as sk\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from collections import deque"
      ],
      "metadata": {
        "id": "yqOPvv-24bR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieve market data \n"
      ],
      "metadata": {
        "id": "b8yg00YT7xZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from alpaca_trade_api.rest import REST, TimeFrame, TimeFrameUnit\n",
        "# Secret key must to be changed if regenerating the key id\n",
        "api_key = 'AK2BNNAGRJPM2CZBC488'\n",
        "secret_key = 'Gi5WCKBIxf5CkTSBor5jiFS910n8TqAbbKQzUT4V'\n",
        "\n",
        "# api = REST(api_key, secret_key)\n",
        "# start_date = '2021-01-01'; end_date = '2022-01-01'\n",
        "# btc_bars = api.get_crypto_bars('BTCUSD', TimeFrame.Day, start_date, end_date).df # get_trades, get_quotes, ETHUSD\n",
        "# btc_bars\n",
        "# stock_choice = 'TSLA' # 'AAPL','AMD','AMZN','FB','GOOG','GOOGL','MSFT','NFLX','NVDA'\n",
        "# stock_bars = api.get_bars(stock_choice, TimeFrame.Day, start_date, end_date).df\n",
        "# stock_bars"
      ],
      "metadata": {
        "id": "P0LAy-QH71En"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieve news data"
      ],
      "metadata": {
        "id": "qz_qE_j0xaCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from alpaca_trade_api.stream import Stream\n",
        "# For historic data use the REST class, for live data use the Stream class\n",
        "rest_client = REST(api_key, secret_key)\n",
        "stream_client = Stream(api_key, secret_key)"
      ],
      "metadata": {
        "id": "U5qLyRVNxZBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformer sentiment analysis using (HuggingFace) BERT network"
      ],
      "metadata": {
        "id": "gp-cF52-0Bf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "model_names = ['distilbert-base-uncased-finetuned-sst-2-english',\n",
        "               'finiteautomata/bertweet-base-sentiment-analysis',\n",
        "               'fhamborg/roberta-targeted-sentiment-classification-newsarticles',\n",
        "               'mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis']\n",
        "\n",
        "classifier = pipeline('sentiment-analysis', model = model_names[-1])\n",
        "\n",
        "def news_data_processor(news):\n",
        "  date = str(news.created_at)[:10]\n",
        "  summary = news.summary\n",
        "  headline = news.headline\n",
        "  text = headline + ' ' + summary\n",
        "  word_list = word_tokenize(text)\n",
        "  words = [word for word in word_list if word.isalpha()]\n",
        "\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  filtered_words = [w for w in words if not w in stop_words]\n",
        "\n",
        "  sentence = ' '.join(filtered_words)\n",
        "  sentiment = classifier(sentence)\n",
        "\n",
        "  return sentence, sentiment, date"
      ],
      "metadata": {
        "id": "akgY-Bdw0KHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DQRL_Trader():\n",
        "\n",
        "  def __init__(self, state_size, action_space=3):\n",
        "    self.state_size = state_size\n",
        "    self.action_space = action_space    \n",
        "    self.memory = deque(maxlen=1500)\n",
        "    self.inventory = []\n",
        "    self.n_data_inputs = 6 # open, open_avg_diff_5_days, open_avg_diff_5_days, portfolio_value, number_of_stocks, sentiment (=6 if including sentiment)\n",
        "\n",
        "    self.gamma = 0.95\n",
        "    self.epsilon = 1.0\n",
        "    self.epsilon_min = 0.1\n",
        "    self.epsilon_decay = 0.995\n",
        "    self.learning_rate = 0.001\n",
        "\n",
        "    self.model = self.model_builder()\n",
        "\n",
        "  def model_builder(self):\n",
        "    init = tf.keras.initializers.HeUniform(seed=1)\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(64, activation='relu', input_shape=(self.n_data_inputs,1), kernel_initializer=init),\n",
        "        tf.keras.layers.Dense(64, activation='relu', kernel_initializer=init),\n",
        "        tf.keras.layers.Dense(64, activation='relu', kernel_initializer=init),\n",
        "        # tf.keras.layers.Dense(64, activation='relu', kernel_initializer=init),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(self.action_space, activation='linear', kernel_initializer=init)\n",
        "    ])\n",
        "    model.compile(loss=tf.keras.losses.Huber(), optimizer=tf.keras.optimizers.Adam(learning_rate=self.learning_rate))\n",
        "    return model \n",
        "\n",
        "  def trade(self, state):\n",
        "    if random.random() <= self.epsilon:\n",
        "      return random.randrange(self.action_space)\n",
        "    else:\n",
        "      options = self.model.predict(state)\n",
        "      # print('options', options)\n",
        "    return np.argmax(options[0])\n",
        "\n",
        "  def batch_Q_learn(self, batch_size):\n",
        "    mini_batch = []\n",
        "    Mem = len(self.memory)\n",
        "    # print('len(self.memory) = ', Mem)\n",
        "    for i in range(Mem - batch_size + 1, Mem):\n",
        "      mini_batch.append(self.memory[i])\n",
        "\n",
        "    for state, action, reward, next_state, done in mini_batch:\n",
        "      target = reward\n",
        "      if not done:\n",
        "        target = reward + self.gamma * np.amax(self.model.predict(next_state))\n",
        "\n",
        "      target_func = self.model.predict(state)\n",
        "      # print('state ', state)\n",
        "      # print('action ', action)\n",
        "      target_func[0][action] = target\n",
        "      self.model.fit(state, target_func, epochs=1, verbose=0)\n",
        "\n",
        "      if self.epsilon > self.epsilon_min:\n",
        "        self.epsilon *= self.epsilon_decay\n"
      ],
      "metadata": {
        "id": "-AfsgVbW2vJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def price_format(p):\n",
        "  return ('-$' if p<0 else '$') + '{0:.2f}'.format(abs(p))\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))"
      ],
      "metadata": {
        "id": "LChk2IAKKtKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# N-day state representation ending at time t\n",
        "def create_state(data, time_step, window_size, portfolio, n_stocks):\n",
        "  start_index = time_step - window_size + 1\n",
        "  data_window = data[start_index : time_step+1] if start_index >= 0 else (-start_index * [data[0]]) + list(data[0 : time_step+1])\n",
        "  # print(len(data_window), window_size)\n",
        "  state=[]\n",
        "  for i in range(len(data_window) -1):\n",
        "    indicators = sigmoid(data_window[i+1] - data_window[i]).flatten()\n",
        "    joint = [*indicators, portfolio, n_stocks]\n",
        "    state.append(joint)\n",
        "    # print(sigmoid(data_window[i+1] - data_window[i]))\n",
        "\n",
        "  return np.array(state).astype('float32')"
      ],
      "metadata": {
        "id": "qbIECTSf229s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_date = '2020-01-01'; end_date = '2022-01-01'\n",
        "stock_choice = 'TSLA' # 'AAPL','AMD','AMZN','FB','GOOG','GOOGL','MSFT','NFLX','NVDA'\n",
        "stock_bars = rest_client.get_bars(stock_choice, TimeFrame.Day, start_date, end_date).df\n",
        "\n",
        "# stream_client.subscribe_news(live_news_data, stock_choice)\n",
        "# stream_client.run()\n",
        "\n",
        "def create_date_arr(data):\n",
        "  stock_date_list = []\n",
        "  for i in range(len(data)):\n",
        "    date_str = str(data.index[i])[:10]\n",
        "    stock_date_list.append(date_str)\n",
        "  return np.array(stock_date_list)\n",
        "\n",
        "stock_open = stock_bars['open']\n",
        "stock_dates = create_date_arr(stock_bars)\n",
        "# print(stock_dates)\n",
        "\n",
        "# Compute the difference between the opening price of a day with the mean opening price over a previous set of days e.g. 5 and 50\n",
        "def avg_open_diff(open_price_data, n_days, start_index):\n",
        "  # if start_index < n_days:\n",
        "  #   print('Beware the moving average difference in opening price is only computed over the last {} day(s), as opposed to {}.'.format(start_index, n_days))\n",
        "  if start_index < len(open_price_data):\n",
        "    start_price = open_price_data[start_index]\n",
        "    prior_avg_price = open_price_data[start_index-n_days : start_index].mean()\n",
        "    diff = start_price - prior_avg_price if start_index-n_days >= 0 else start_price - open_price_data[:start_index].mean()\n",
        "    return diff\n",
        "  else:\n",
        "    return IndexError('Failed to compute moving average difference: invalid request')\n",
        "\n",
        "def create_avg_diff_data(data, n):\n",
        "  stock_avg_diff_n = [0] # avg diff = 0 for first open price\n",
        "  for i in range(1, len(data)):\n",
        "    stock_avg_diff_n_i = avg_open_diff(data, n, i)\n",
        "    stock_avg_diff_n.append(stock_avg_diff_n_i)\n",
        "  return np.array(stock_avg_diff_n)\n",
        "\n",
        "stock_avg_diff_5 = create_avg_diff_data(stock_open, 5)\n",
        "stock_avg_diff_50 = create_avg_diff_data(stock_open, 50)\n",
        "\n",
        "stock_data = np.transpose([stock_open, stock_avg_diff_5, stock_avg_diff_50])#.astype(np.float16)\n",
        "\n",
        "news = rest_client.get_news(stock_choice, start_date, end_date, limit=10000)\n",
        "\n",
        "N_news = len(news)\n",
        "NEG, POS, NEU = 0, 0, 0\n",
        "news_data_arr = []\n",
        "news_dates = []\n",
        "for i in range(N_news):\n",
        "  article_text, sentim, news_date = news_data_processor(news[i])\n",
        "  if news_date in stock_dates:\n",
        "    # print(news_date)\n",
        "    sentim_label = sentim[0]['label']\n",
        "    sentim_score = float(sentim[0]['score'])\n",
        "    if sentim_label == 'negative':\n",
        "      score = sentim_score * -1\n",
        "      # NEG+=1\n",
        "    elif sentim_label == 'positive':\n",
        "      score = sentim_score\n",
        "      # POS+=1\n",
        "    elif sentim_label == 'neutral':\n",
        "      score = 0.0\n",
        "      # NEU+=1\n",
        "    news_data_arr.append([score, news_date])\n",
        "    news_dates.append(news_date)\n",
        "    # news_data_arr.insert(i, [article_text, sentim[0]['label'], sentim[0]['score'], news_date]) if reversing time ordering (as news data is read in from end -> start date)\n",
        "    # news_data_arr.append([article_text, sentim[0]['label'], sentim[0]['score'], news_date])\n",
        "  else:\n",
        "    continue\n",
        "\n",
        "# print(NEG, POS, NEU)\n",
        "# print(news_data_arr)\n",
        "news_data_reverse = news_data_arr[::-1]\n",
        "news_dates_reverse_array = np.asarray(news_data_reverse)\n",
        "\n",
        "# Sort by date-time\n",
        "def sort_DT(data):\n",
        "  return sorted(data, key=lambda x: datetime.datetime.strptime(x, '%Y-%m-%d'))\n",
        "\n",
        "unique_sorted_news_dates = np.array(sort_DT(list(set(news_dates))))\n",
        "sentiment_scores = []\n",
        "for unique_date in unique_sorted_news_dates:\n",
        "  # print(unique_date)\n",
        "  date_indexes = np.where(unique_date == news_dates_reverse_array)[0]\n",
        "  # print(news_dates_reverse_array[index_,0])\n",
        "  float_scores = [float(i) for i in news_dates_reverse_array[date_indexes,0]]\n",
        "  avg_score = np.mean(float_scores)\n",
        "  sentiment_scores.append(avg_score)\n",
        "\n",
        "sentiment_scores = np.array(sentiment_scores)\n",
        "\n",
        "if len(stock_data) != len(sentiment_scores):\n",
        "  print('Error in processing sentiment scores/ start-end dates misaligned for news and market data')\n"
      ],
      "metadata": {
        "id": "GWumupswAW56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_sentiment_data = np.hstack((stock_data, np.expand_dims(sentiment_scores, axis=1)))\n",
        "print(stock_sentiment_data)"
      ],
      "metadata": {
        "id": "4147Adrb_9R1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_size = 5 # days inbetween action e.g. buy/sell/sit\n",
        "epochs = 1000\n",
        "batch_size = 32\n",
        "data = stock_sentiment_data     # stock_data     \n",
        "N_data = len(data)-1\n",
        "\n",
        "trader = DQRL_Trader(window_size)\n",
        "trader.model.summary()"
      ],
      "metadata": {
        "id": "Fo5fUuqi1dr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  print('Epoch {}/{} ...'.format(epoch+1, epochs))\n",
        "\n",
        "  # state = create_state(data, 0, window_size+1)\n",
        "  trader.inventory = []\n",
        "  total_profit = 0\n",
        "  n_stocks_owned = 10\n",
        "  initial_funds = 1000\n",
        "  portfolio_value = (n_stocks_owned * data[0][0]) + initial_funds\n",
        "  print('Initial portfolio value: {} | Number of stocks: {}'.format(price_format(portfolio_value), n_stocks_owned))\n",
        "\n",
        "  state = create_state(data, 0, window_size+1, portfolio_value, n_stocks_owned)\n",
        "  # print(state.shape)\n",
        "\n",
        "  for t in range(N_data):\n",
        "    action = trader.trade(state)\n",
        "    # next_state = create_state(data, t+1, window_size+1)\n",
        "    next_state = create_state(data, t+1, window_size+1, portfolio_value, n_stocks_owned)\n",
        "    # print(next_state.shape)\n",
        "    reward = 0\n",
        "\n",
        "    if portfolio_value < data[t][0] or n_stocks_owned == 0: # punish inability to buy/sell stock\n",
        "      reward = -10\n",
        "\n",
        "    if portfolio_value < data[t][0] and n_stocks_owned == 0: # huge penalty for bankcruptcy\n",
        "      reward = -100 \n",
        "\n",
        "    if action == 0: # punish repeated sitting over time\n",
        "      print('Sitting...')\n",
        "      reward = -0.1\n",
        "    \n",
        "    elif action == 1 and portfolio_value >= data[t][0]: # buy\n",
        "      n_stocks_owned += 1\n",
        "      portfolio_value -= data[t][0]\n",
        "      trader.inventory.append(data[t])\n",
        "      print('Trader bought a stock for {}'.format(price_format(data[t][0])))\n",
        "      print('Total portfolio value: {} | Number of stocks: {}'.format(price_format(portfolio_value), n_stocks_owned))\n",
        "\n",
        "    elif action == 2 and len(trader.inventory) > 0: # sell\n",
        "      bought_price = trader.inventory.pop(0)\n",
        "      n_stocks_owned -= 1\n",
        "      portfolio_value += data[t][0]\n",
        "      # print('bought_price: ', bought_price)\n",
        "      if data[t][0] - bought_price[0] > 0:\n",
        "        reward = 1\n",
        "      elif data[t][0] - bought_price[0] == 0:\n",
        "        reward = 0\n",
        "      else:\n",
        "        reward = -1\n",
        "\n",
        "      total_profit += data[t][0] - bought_price[0]\n",
        "      print('Trader sold one stock at {} | Transaction profit: {}'.format(price_format(data[t][0]), price_format(data[t][0] - bought_price[0])))\n",
        "      print('Total portfolio value: {} | Number of stocks: {}'.format(price_format(portfolio_value), n_stocks_owned))\n",
        "\n",
        "    done = True if t == N_data-1 else False\n",
        "\n",
        "    trader.memory.append([state, action, reward, next_state, done])\n",
        "    # print('memory', trader.memory)\n",
        "    state = next_state\n",
        "\n",
        "    if done:\n",
        "      print('\\n Total profit = {} \\n'.format(price_format(total_profit)))\n",
        "\n",
        "    if len(trader.memory) > batch_size:\n",
        "      trader.batch_Q_learn(batch_size)\n",
        "    else:\n",
        "      continue"
      ],
      "metadata": {
        "id": "MpZu4kfN_dPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# state_data, action_data = [], []\n",
        "# for i in range(len(trader.memory)):\n",
        "#   state_data.append(np.squeeze(trader.memory[i][0]))\n",
        "#   action_data.append(np.squeeze(trader.memory[i][1]))  \n"
      ],
      "metadata": {
        "id": "gob_9-SiLnh7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}